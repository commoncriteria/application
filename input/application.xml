<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="..	ransformspp2html.xsl"?>
<?xml-model href="https://raw.githubusercontent.com/commoncriteria/transforms/master/schemas/CCProtectionProfile.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<PP boilerplate="yes" target-product="Application Software" target-products="Application Software" xmlns="https://niap-ccevs.org/cc/v1" xmlns:h="http://www.w3.org/1999/xhtml" xmlns:sec="https://niap-ccevs.org/cc/v1/section" short="App">
  <PPReference>
    <ReferenceTable>
      <PPTitle>Protection Profile for Application Software</PPTitle>
      <PPVersion>1.4</PPVersion>
      <PPAuthor>National Information Assurance Partnership</PPAuthor>
      <PPPubDate>2021-10-07</PPPubDate>
      <Keywords>application; software</Keywords>
    </ReferenceTable>
  </PPReference>
  <RevisionHistory>
    <entry>
      <version>v 1.0</version>
      <date>2014-10-20</date>
      <subject>Initial release</subject>
    </entry>
    <entry>
      <version>v 1.1</version>
      <date>2014-11-05</date>
      <subject>Addition to TLS cipher suite selections</subject>
    </entry>
    <entry>
      <version>v 1.2</version>
      <date>2016-04-22</date>
      <subject>Added server-side TLS requirements (selection-based)<h:br/>Multiple clarification based on NIAP TRRT inquiries<h:br/>Refactored FDP_DEC_EXT.1 into separate components<h:br/></subject>
    </entry>
    <entry>
      <version>v 1.3</version>
      <date>2019-03-01</date>
      <subject>Incorporated available Technical Decisions<h:br/>Refactored FPT_TUD<h:br/>Added a selection to FTP_DIT<h:br/>Moved SWID Tags requirement<h:br/>Leveraged TLS Package<h:br/>Added equivalency section<h:br/></subject>
    </entry>
    <entry>
      <version>v 1.4</version>
      <date>2021-10-07</date>
      <subject>Incorporated applicable Technical Decisions<h:br/>Updated to TLS FP 1.1<h:br/>Incorporated SSH FP 1.0<h:br/></subject>
    </entry>
  </RevisionHistory>
  <include-pkg id="pkg-tls">
    <git>
      <url>https://github.com/commoncriteria/tls</url>
      <branch>v1.1</branch>
    </git>
    <url>https://www.niap-ccevs.org/Profile/Info.cfm?PPID=439&amp;id=439</url>
    <depends on-sel="sel_all_tls"/>
    <depends on-also="sel_all_dtls"/>
  </include-pkg>
  <include-pkg id="pkg-ssh">
    <git>
      <url>https://github.com/commoncriteria/ssh</url>
      <branch>v1.0</branch>
    </git>
    <url>https://www.niap-ccevs.org/Profile/Info.cfm?PPID=459&amp;id=459</url>
    <depends on-sel="sel_all_ssh"/>
  </include-pkg>
  <modules/>
  <pp-preferences/>
  <sec:Introduction >
    <sec:Overview/>
    <tech-terms/>
    <section title="Compliant Targets of Evaluation" id="TOEdescription"/>
    <section title="Platforms with Specific EAs" id="sec-platforms"><choice prefix="Platforms:">This PP includes platform-specific EAs for the below-listed operating system platforms. For "bare-metal" applications, applications that run on other OS platforms, and applications that run in software-based execution environments contact the Technical Community for guidance.<h:p/><selectables linebreak="yes"><selectable id="android"><h:b>Android</h:b>:<h:i>Mobile operating systems based on Google Android.</h:i></selectable><selectable id="windows"><h:b>Microsoft Windows</h:b>:<h:i>Microsoft Windows operating systems.</h:i></selectable><selectable id="ios"><h:b>Apple iOS</h:b>:<h:i>Apple's mobile operating system for iPhones.</h:i></selectable><selectable id="linux"><h:b>Linux</h:b>:<h:i>Linux-based operating systems other than Android.</h:i></selectable><selectable id="Solaris"><h:b>Oracle Solaris</h:b>:<h:i>Oracle's enterprise operating system.</h:i></selectable><selectable id="mac"><h:b>Apple macOS</h:b>:<h:i>Apple's operating system for MACs.</h:i></selectable></selectables></choice></section>
    <sec:Use_Cases/>
  </sec:Introduction>
  <sec:Conformance_Claims  boilerplate="no">
    <cclaims>
      <cclaim name="Conformance Statement">
        <description/>
      </cclaim>
      <cclaim name="CC Conformance Claims">
        <description/>
      </cclaim>
      <cclaim name="PP Claims">
        <description/>
      </cclaim>
      <cclaim name="Package Claims">
        <description/>
      </cclaim>
    </cclaims>
  </sec:Conformance_Claims>
  <!-- 3.0 Security Problem Definition-->
  <sec:Security_Problem_Definition >
    
		The security problem is described in terms
		of the threats that the TOE is expected to address, assumptions about the
		operational environment, and any organizational security policies that the TOE
		is expected to enforce.
		
	
    <!-- 3.1 Threats -->
    <sec:Threats>
      <threats/>
    </sec:Threats>
    <!-- 3.2 Assumptions -->
    <sec:Assumptions>
      <assumptions/>
    </sec:Assumptions>
    <!-- 3.3 Organizational Security Policies -->
    <sec:Organizational_Security_Policies>
      <OSPs/>
      <!--     <OSP id="P.QQQQ"> 
        <description>QQQQ</description>
        <objective-refer ref="O.QQQQ">
            <rationale>QQQQ</rationale>
        </objective-refer>
    </OSP>
    </OSPs> -->
    </sec:Organizational_Security_Policies>
  </sec:Security_Problem_Definition>
  <!-- 4.0 Security Objectives -->
  <sec:Security_Objectives >
    <!-- 4.1 Security Objectives for the TOE -->
    <sec:Security_Objectives_for_the_TOE>
      <SOs/>
    </sec:Security_Objectives_for_the_TOE>
    <!-- 4.2 Security Objctives for the Operational Environment -->
    <sec:Security_Objectives_for_the_Operational_Environment>
      <SOEs/>
    </sec:Security_Objectives_for_the_Operational_Environment>
    <!-- 4.3 Security Objectives Rationale -->
    <sec:Security_Objectives_Rationale/>
  </sec:Security_Objectives>
  <!-- 5.0 Security Requirements -->
  <sec:req  title="Security Requirements">
    <!-- 5.1 Security Functional Requirements-->
    <sec:SFRs title="Security Functional Requirements"/>
    <!--5.2 Security Assurance Requirements-->
    <section title="Security Assurance Requirements" id="SARs"/>
  </sec:req>
  <appendix title="Entropy Documentation and Assessment" id="entropyappendix">This appendix describes the required supplementary information for the entropy source used by the TOE.<h:br></h:br>The documentation of the entropy source should be detailed enough that, after reading, the evaluator will thoroughly understand the entropy source and why it can be relied upon to provide sufficient entropy. This documentation should include multiple detailed sections: design description, entropy justification, operating conditions, and health testing. This documentation is not required to be part of the TSS.<section id="entropydesign" title="Design Description">Documentation shall include the design of the entropy source as a whole, including the interaction of all entropy source components. Any information that can be shared regarding the design should also be included for any third-party entropy sources that are included in the product.<h:br></h:br>The documentation will describe the operation of the entropy source to include, how entropy is produced, and how unprocessed (raw) data can be obtained from within the entropy source for testing purposes. The documentation should walk through the entropy source design indicating where the entropy comes from, where the entropy output is passed next, any post-processing of the raw outputs (hash, XOR, etc.), if/where it is stored, and finally, how it is output from the entropy source. Any conditions placed on the process (e.g., blocking) should also be described in the entropy source design. Diagrams and examples are encouraged.<h:br></h:br>This design must also include a description of the content of the security boundary of the entropy source and a description of how the security boundary ensures that an adversary outside the boundary cannot affect the entropy rate.<h:br></h:br>If implemented, the design description shall include a description of how third-party applications can add entropy to the RBG. A description of any RBG state saving between power-off and power-on shall be included.</section><section id="entropyjustification" title="Entropy Justification">There should be a technical argument for where the unpredictability in the source comes from and why there is confidence in the entropy source delivering sufficient entropy for the uses made of the RBG output (by this particular TOE). This argument will include a description of the expected min-entropy rate (i.e. the minimum entropy (in bits) per bit or byte of source data) and explain that sufficient entropy is going into the TOE randomizer seeding process. This discussion will be part of a justification for why the entropy source can be relied upon to produce bits with entropy.<h:br></h:br>The amount of information necessary to justify the expected min-entropy rate depends on the type of entropy source included in the product.<h:br></h:br>For developer provided entropy sources, in order to justify the min-entropy rate, it is expected that a large number of raw source bits will be collected, statistical tests will be performed, and the min-entropy rate determined from the statistical tests. While no particular statistical tests are required at this time, it is expected that some testing is necessary in order to determine the amount of min-entropy in each output.<h:br></h:br>For third party provided entropy sources, in which the TOE vendor has limited access to the design and raw entropy data of the source, the documentation will indicate an estimate of the amount of min-entropy obtained from this third-party source. It is acceptable for the vendor to “assume” an amount of min-entropy, however, this assumption must be clearly stated in the documentation provided. In particular, the min-entropy estimate must be specified and the assumption included in the ST.<h:br></h:br>Regardless of type of entropy source, the justification will also include how the DRBG is initialized with the entropy stated in the ST, for example by verifying that the min-entropy rate is multiplied by the amount of source data used to seed the DRBG or that the rate of entropy expected based on the amount of source data is explicitly stated and compared to the statistical rate. If the amount of source data used to seed the DRBG is not clear or the calculated rate is not explicitly related to the seed, the documentation will not be considered complete.<h:br></h:br>The entropy justification shall not include any data added from any third-party application or from any state saving between restarts.</section><section id="entropyoperatingconditions" title="Operating Conditions">The entropy rate may be affected by conditions outside the control of the entropy source itself. For example, voltage, frequency, temperature, and elapsed time after power-on are just a few of the factors that may affect the operation of the entropy source. As such, documentation will also include the range of operating conditions under which the entropy source is expected to generate random data. It will clearly describe the measures that have been taken in the system design to ensure the entropy source continues to operate under those conditions. Similarly, documentation shall describe the conditions under which the entropy source is known to malfunction or become inconsistent. Methods used to detect failure or degradation of the source shall be included.</section><section id="entropyhealthtesting" title="Health Testing">More specifically, all entropy source health tests and their rationale will be documented. This will include a description of the health tests, the rate and conditions under which each health test is performed (e.g., at startup, continuously, or on-demand), the expected results for each health test, and rationale indicating why each test is believed to be appropriate for detecting one or more failures in the entropy source.</section></appendix>
  <appendix title="Application Software Equivalency Guidelines" id="equiv"><section id="app-intro" title="Introduction">The purpose of equivalence in PP-based evaluations is to find a balance between evaluation rigor and commercial practicability—to ensure that evaluations meet customer expectations while recognizing that there is little to be gained from requiring that every variation in a product or platform be fully tested. If a product is found to be compliant with a PP on one platform, then all equivalent products on equivalent platforms are also considered to be compliant with the PP.<h:br></h:br><h:br></h:br>A Vendor can make a claim of equivalence if the Vendor believes that a particular instance of their Product implements PP-specified security functionality in a way equivalent to the implementation of the same functionality on another instance of their Product on which the functionality was tested. The Product instances can differ in version number or feature level (model), or the instances may run on different platforms. Equivalency can be used to reduce the testing required across claimed evaluated configurations. It can also be used during Assurance Maintenance to reduce testing needed to add more evaluated configurations to a certification.<h:br></h:br><h:br></h:br>These equivalency guidelines do not replace Assurance Maintenance requirements or NIAP Policy #5 requirements for CAVP certificates. Nor may equivalency be used to leverage evaluations with expired certifications.<h:br></h:br><h:br></h:br>These Equivalency Guidelines represent a shift from complete testing of all product instances to more of a risk-based approach. Rather than require that every combination of product and platform be tested, these guidelines support an approach that recognizes that products are being used in a variety of environments—and often in cloud environments over where the vendor (and sometimes the customer) have little or no control over the underlying hardware. Developers should be responsible for the security functionality of their applications on the platforms they are developed for—whether that is an operating system, a virtual machine, or a software-based execution environment such as a container. But those platforms may themselves run within other environments—virtual machines or operating systems—that completely abstract away the underlying hardware from the application. The developer should not be held accountable for security functionality that is implemented by platform layers that are abstracted away. The implication is that not all security functionality will necessarily be tested for all platform layers down to the hardware for all evaluated configurations—especially for applications developed for software-based execution environments such as containers. For these cases, the balancing of evaluation rigor and commercial practicability tips in favor of practicability. Note that this does not affect the requirement that at least one product instance be fully tested on at least one platform with cryptography mapped to a CAVP certificate.<h:br></h:br><h:br></h:br>Equivalency has two aspects:<h:br></h:br><h:ol><h:li><h:b><h:i>Product Equivalence:</h:i></h:b>Products may be considered equivalent if there are no differences between Product Models and Product Versions with respect to PP-specified security functionality.</h:li><h:li><h:b><h:i>Platform Equivalence:</h:i></h:b>Platforms may be considered equivalent if there are no significant differences in the services they provide to the Product—or in the way the platforms provide those services—with respect to PP-specified security functionality.</h:li></h:ol>The equivalency determination is made in accordance with these guidelines by the Validator and Scheme using information provided by the Evaluator/Vendor.</section><section id="approach" title="Approach to Equivalency Analysis">There are two scenarios for performing equivalency analysis. One is when a product has been certified and the vendor wants to show that a later product should be considered certified due to equivalence with the earlier product. The other is when multiple product variants are going though evaluation together and the vendor would like to reduce the amount of testing that must be done. The basic rules for determining equivalence are the same in both cases. But there is one additional consideration that applies to equivalence with previously certified products. That is, the product with which equivalence is being claimed must have a valid certification in accordance with scheme rules and the Assurance Maintenance process must be followed. If a product’s certification has expired, then equivalence cannot be claimed with that product.<h:br></h:br><h:br></h:br>When performing equivalency analysis, the Evaluator/Vendor should first use the factors and guidelines for Product Model equivalence to determine the set of Product Models to be evaluated. In general, Product Models that do not differ in PP-specified security functionality are considered equivalent for purposes of evaluation against the AppPP.<h:br></h:br><h:br></h:br>If multiple revision levels of Product Models are to be evaluated—or to determine whether a revision of an evaluated product needs re-evaluation—the Evaluator/Vendor and Validator should use the factors and guidelines for Product Version equivalence to analyze whether Product Versions are equivalent.<h:br></h:br><h:br></h:br>Having determined the set of Product Models and Versions to be evaluated, the next step is to determine the set of Platforms that the Products must be tested on.<h:br></h:br><h:br></h:br>Each non-equivalent Product for which compliance is claimed must be fully tested on each non-equivalent platform for which compliance is claimed. For non-equivalent Products on equivalent platforms, only the differences that affect PP-specified security functionality must be tested for each product.<h:br></h:br><h:br></h:br><h:b><h:i>“Differences in PP-Specified Security Functionality” Defined</h:i></h:b><h:br></h:br>If PP-specified security functionality is implemented by the TOE, then differences in the actual implementation between versions or product models break equivalence for that feature. Likewise, if the TOE implements the functionality in one version or model and the functionality is implemented by the platform in another version or model, then equivalence is broken. If the functionality is implemented by the platform in multiple models or versions on equivalent platforms, then the functionality is considered different if the product invokes the platform differently to perform the function.</section><section id="modelequiv" title="Specific Guidance for Determining Product Model Equivalence">Product Model equivalence attempts to determine whether different feature levels of the same product across a product line are equivalent for purposes of PP testing. For example, if a product has a “basic” edition and an “enterprise” edition, is it necessary to test both models? Or does testing one model provide sufficient assurance that both models are compliant?<h:br></h:br><h:br></h:br>Product models are considered equivalent if there are no differences that affect PP-specified security functionality—as indicated in Table 1.<h:br></h:br><h:br></h:br><h:table border="1"><h:tr class="header" bgcolor="#cccccc"><h:td valign="top">Factor</h:td><h:td valign="top">Same/Different</h:td><h:td valign="top">Guidance</h:td></h:tr><h:tr><h:td rowspan="2" valign="top">PP-Specified Functionality</h:td><h:td valign="top">Same</h:td><h:td valign="top">If the differences between Models affect only non-PP-specified functionality, then the Models are equivalent.</h:td></h:tr><h:tr><h:td valign="top">Different</h:td><h:td valign="top">If PP-specified security functionality is affected by the differences between Models, then the Models are not equivalent and must be tested separately. It is necessary only to test the functionality affected by the software differences. If only differences are tested, then the differences must be enumerated, and for each difference the Vendor must provide an explanation of why each difference does or does not affect PP-specified functionality. If the Product Models are separately tested fully, then there is no need to document the differences.</h:td></h:tr></h:table><h:b>Table 1. Determining Product Model Equivalence</h:b><h:br></h:br><h:br></h:br></section><section id="versionequiv" title="Specific Guidance for Determining Product Version Equivalence">In cases of version equivalence, differences are expressed in terms of changes implemented in revisions of an evaluated Product. In general, versions are equivalent if the changes have no effect on any security-relevant claims about the TOE or assurance evidence. Non-security-relevant changes to TOE functionality or the addition of non-security-relevant functionality does not affect equivalence.<h:br></h:br><h:br></h:br><h:table border="1"><h:tr class="header" bgcolor="#cccccc"><h:td valign="top">Factor</h:td><h:td valign="top">Same/Different</h:td><h:td valign="top">Guidance</h:td></h:tr><h:tr valign="top"><h:td valign="top">Product Models</h:td><h:td valign="top">Different</h:td><h:td valign="top">Versions of different Product Models are not equivalent unless the Models are equivalent as defined in Section 3.</h:td></h:tr><h:tr><h:td rowspan="2" valign="top">PP-Specified Functionality</h:td><h:td valign="top">Same</h:td><h:td valign="top">If the differences affect only non-PP-specified functionality, then the Versions are equivalent.</h:td></h:tr><h:tr><h:td valign="top">Different</h:td><h:td valign="top">If PP-specified security functionality is affected by the differences, then the Versions are not considered equivalent and must be tested separately. It is necessary only to test the functionality affected by the changes. If only the differences are tested, then for each difference the Vendor must provide an explanation of why the difference does or does not affect PP-specified functionality. If the Product Versions are separately tested fully, then there is no need to document the differences.</h:td></h:tr></h:table><h:b>Table 2. Factors for Determining Product Version Equivalence</h:b><h:br></h:br><h:br></h:br></section><section id="platformequiv" title="Specific Guidance for Determining Platform Equivalence">Platform equivalence is used to determine the platforms that equivalent versions of a Product must be tested on. Platform equivalence analysis done for one software application cannot be applied to another software application. Platform equivalence is not general—it is with respect to a particular application.<h:br></h:br><h:br></h:br>Product Equivalency analysis must already have been done and Products have been determined to be equivalent.<h:br></h:br><h:br></h:br>The platform can be hardware or virtual hardware, an operating system or similar entity, or a software execution environment such as a container. For purposes of determining equivalence for software applications, we address each type of platform separately. In general, platform equivalence is based on differences in the interfaces between the TOE and Platform that are relevant to the implementation of PP-specified security functionality.<h:br></h:br><h:br></h:br><section id="hardware-equiv" title="Platform Equivalence—Hardware/Virtual Hardware Platforms">If an Application runs directly on hardware without an operating system—or directly on virtualized hardware without an operating system—then platform equivalence is based on processor architecture and instruction sets. In the case of virtualized hardware, it is the virtualized processor and architecture that are presented to the application that matters—not the physical hardware.<h:br></h:br><h:br></h:br>Platforms with different processor architectures and instruction sets are not equivalent. This is not likely to be an issue for equivalency analysis for applications since there is likely to be a different version of the application for different hardware environments. Equivalency analysis becomes important when comparing processors with the same architecture. Processors with the same architecture that have instruction sets that are subsets or supersets of each other are not disqualified from being equivalent for purposes of an App evaluation. If the application takes the same code paths when executing PP-specified security functionality on different processors of the same family, then the processors can be considered equivalent with respect to that application. For example, if an application follows one code path on platforms that support the AES-NI instruction and another on platforms that do not, then those two platforms are not equivalent with respect to that application functionality. But if the application follows the same code path whether or not the platform supports AES-NI, then the platforms are equivalent with respect to that functionality.<h:br></h:br><h:br></h:br>The platforms are equivalent with respect to the application if the platforms are equivalent with respect to all PP-specified security functionality.<h:table border="1"><h:tr class="header" bgcolor="#cccccc"><h:td valign="top">Factor</h:td><h:td valign="top">Same/Different/None</h:td><h:td valign="top">Guidance</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Architectures</h:td><h:td valign="top">Different</h:td><h:td valign="top">Platforms that present different processor architectures and instruction sets to the application are not equivalent.</h:td></h:tr><h:tr><h:td valign="top">PP-Specified Functionality</h:td><h:td valign="top">Same</h:td><h:td valign="top">For platforms with the same processor architecture, the platforms are equivalent with respect to the application if execution of all PP-specified security functionality follows the same code path on both platforms.</h:td></h:tr></h:table><h:b>Table 3. Factors for Determining Hardware/Virtual Hardware Platform Equivalence</h:b><h:br></h:br><h:br></h:br></section><section id="os-equiv" title="Platform Equivalence—OS Platforms">For traditional applications that are built for and run on operating systems, platform equivalence is determined by the interfaces between the application and the operating system that are relevant to PP-specified security functionality. Generally, these are the processor interface, device interfaces, and OS APIs. The following factors applied in order:<h:table border="1"><h:tr class="header" bgcolor="#cccccc"><h:td valign="top">Factor</h:td><h:td valign="top">Same/Different/None</h:td><h:td valign="top">Guidance</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Architectures</h:td><h:td valign="top">Different</h:td><h:td valign="top">Platforms that run on different processor architectures and instruction sets are not equivalent.</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Vendors</h:td><h:td valign="top">Different</h:td><h:td valign="top">Platforms from different vendors are not equivalent.</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Versions</h:td><h:td valign="top">Different</h:td><h:td valign="top">Platforms from the same vendor with different major version numbers are not equivalent.</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Interfaces</h:td><h:td valign="top">Different</h:td><h:td valign="top">Platforms from the same vendor and major version are not equivalent if there are differences in device interfaces and OS APIs that are relevant to the way the platform provides PP-specified security functionality to the application.</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Interfaces</h:td><h:td valign="top">Same</h:td><h:td valign="top">Platforms from the same vendor and major version are equivalent if there are no differences in device interfaces and OS APIs that are relevant to the way the platform provides PP-specified security functionality to the application, or if the Platform does not provide such functionality to the application.</h:td></h:tr></h:table><h:b>Table 4. Factors for Determining OS/VS Platform Equivalence</h:b><h:br></h:br><h:br></h:br></section><section id="software-equiv" title="Software-based Execution Environment Platform Equivalence">If an Application is built for and runs in a non-OS software-based execution environment, such as a Container or Java Runtime, then the below criteria must be used to determine platform equivalence. The key point is that the underlying hardware (virtual or physical) and OS is not relevant to platform equivalence. This allows applications to be tested and run on software-based execution environments on any hardware—as in cloud deployments.<h:table border="1"><h:tr class="header" bgcolor="#cccccc"><h:td valign="top">Factor</h:td><h:td valign="top">Same/Different/None</h:td><h:td valign="top">Guidance</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Type/Vendor</h:td><h:td valign="top">Different</h:td><h:td valign="top">Software-based execution environments that are substantially different or come from different vendors are not equivalent. For example, a java virtual machine is not the same as a container. A Docker container is not the same as a CoreOS container.</h:td></h:tr><h:tr valign="top"><h:td valign="top">Platform Versions</h:td><h:td valign="top">Different</h:td><h:td valign="top">Execution environments that are otherwise equivalent are not equivalent if they have different major version numbers.</h:td></h:tr><h:tr valign="top"><h:td valign="top">PP-Specified Security Functionality</h:td><h:td valign="top">Same</h:td><h:td valign="top">All other things being equal, execution environments are equivalent if there is no significant difference in the interfaces through which the environments provide PP-specified security functionality to applications.</h:td></h:tr></h:table><h:b>Table 5. Factors for Software-based Execution Environment Platform Equivalence</h:b><h:br></h:br><h:br></h:br></section></section><section id="specificity" title="Level of Specificity for Tested Configurations and Claimed Equivalent Configurations">In order to make equivalency determinations, the vendor and evaluator must agree on the equivalency claims. They must then provide the scheme with sufficient information about the TOE instances and platforms that were evaluated, and the TOE instances and platforms that are claimed to be equivalent.<h:br></h:br><h:br></h:br>The ST must describe all configurations evaluated down to processor manufacturer, model number, and microarchitecture version.<h:br></h:br><h:br></h:br>The information regarding claimed equivalent configurations depends on the platform that the application was developed for and runs on.<h:br></h:br><h:br></h:br><h:b>Bare-Metal Applications</h:b><h:br></h:br><h:br></h:br>For applications that run without an operating system on bare-metal or virtual bare-metal, the claimed configuration must describe the platform down to the specific processor manufacturer, model number, and microarchitecture version. The Vendor must describe the differences in the TOE with respect to PP-specified security functionality and how the TOE functions differently to leverage platform differences (e.g., instruction set extensions) in the tested configuration versus the claimed equivalent configuration.<h:br></h:br><h:br></h:br><h:b>Traditional Applications</h:b><h:br></h:br><h:br></h:br>For applications that run with an operating system as their immediate platform, the claimed configuration must describe the platform down to the specific operating system version. If the platform is a virtualization system, then the claimed configuration must describe the platform down to the specific virtualization system version. The Vendor must describe the differences in the TOE with respect to PP-specified security functionality and how the TOE functions differently to leverage platform differences in the tested configuration versus the claimed equivalent configuration. Relevant platform differences could include instruction sets, device interfaces, and OS APIs invoked by the TOE to implement PP-specified security functionality.<h:br></h:br><h:br></h:br><h:b>Software-Based Execution Environments</h:b><h:br></h:br><h:br></h:br>For applications that run in a software-based execution environment such as a Java virtual machine or a Container, then the claimed configuration must describe the platform down to the specific version of the software execution environment. The Vendor must describe the differences in the TOE with respect to PP-specified security functionality and how the TOE functions differently to leverage platform differences in the tested configuration versus the claimed equivalent configuration.<h:br></h:br></section></appendix>
  <bibliography>
    <cc-entry/>
    <entry id="bibCEM">
      <tag>CEM</tag>
      <description> <h:a href="http://www.commoncriteriaportal.org/files/ccfiles/CEMV3.1R4.pdf">Common
            Evaluation Methodology for Information Technology Security - Evaluation Methodology</h:a>,
          CCMB-2017-04-004, Version 3.1, Revision 5, April 2017. </description>
    </entry>
    <entry id="bibOMB">
      <tag>OMB</tag>
      <description> <h:a href="http://www.whitehouse.gov/sites/default/files/omb/memoranda/fy2006/m06-19.pdf">Reporting Incidents Involving Personally Identifiable Information and Incorporating the
            Cost for Security in Agency Information Technology Investments</h:a>, OMB M-06-19, July
          12, 2006. </description>
    </entry>
  </bibliography>
</PP>
